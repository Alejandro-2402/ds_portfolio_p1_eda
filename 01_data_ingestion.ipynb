{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508d7654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading successful. First 5 rows:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0          892         0       3   \n",
      "1          893         1       3   \n",
      "2          894         0       2   \n",
      "3          895         0       3   \n",
      "4          896         1       3   \n",
      "\n",
      "                                           Name     Sex   Age  SibSp  Parch  \\\n",
      "0                              Kelly, Mr. James    male  34.5      0      0   \n",
      "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
      "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
      "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
      "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "\n",
      "    Ticket     Fare Cabin Embarked  \n",
      "0   330911   7.8292   NaN        Q  \n",
      "1   363272   7.0000   NaN        S  \n",
      "2   240276   9.6875   NaN        Q  \n",
      "3   315154   8.6625   NaN        S  \n",
      "4  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Notebook's title: 01 - Data Ingestion and Initial Inspection\n",
    "\n",
    "# 1. Import the essential library for the data analysis\n",
    "import pandas as pd\n",
    "\n",
    "# 2. Upload the file CSV.\n",
    "# Make sure the file name matches the one you downloaded from Kaggle!\n",
    "# We define data frame as df\n",
    "try:\n",
    "    df = pd.read_csv('train.csv')\n",
    "\n",
    "    # 3. Display the first 5 rows to verify successful upload\n",
    "    print(\"Loading successful. First 5 rows:\") \n",
    "    print(df.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: File 'train.csv' not found. Make sure it is in the same folder as this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18301d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions: (418, 12)\n",
      "\n",
      "Type and null's information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Survived     418 non-null    int64  \n",
      " 2   Pclass       418 non-null    int64  \n",
      " 3   Name         418 non-null    object \n",
      " 4   Sex          418 non-null    object \n",
      " 5   Age          332 non-null    float64\n",
      " 6   SibSp        418 non-null    int64  \n",
      " 7   Parch        418 non-null    int64  \n",
      " 8   Ticket       418 non-null    object \n",
      " 9   Fare         417 non-null    float64\n",
      " 10  Cabin        91 non-null     object \n",
      " 11  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 39.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Structural and types diagnostic\n",
    "\n",
    "print (\"Dataset dimensions:\", df.shape)\n",
    "print (\"\\nType and null's information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d31c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical Summary:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   418.000000  418.000000  418.000000  332.000000  418.000000   \n",
      "mean   1100.500000    0.363636    2.265550   30.272590    0.447368   \n",
      "std     120.810458    0.481622    0.841838   14.181209    0.896760   \n",
      "min     892.000000    0.000000    1.000000    0.170000    0.000000   \n",
      "25%     996.250000    0.000000    1.000000   21.000000    0.000000   \n",
      "50%    1100.500000    0.000000    3.000000   27.000000    0.000000   \n",
      "75%    1204.750000    1.000000    3.000000   39.000000    1.000000   \n",
      "max    1309.000000    1.000000    3.000000   76.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  418.000000  417.000000  \n",
      "mean     0.392344   35.627188  \n",
      "std      0.981429   55.907576  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.895800  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.500000  \n",
      "max      9.000000  512.329200  \n",
      "\n",
      "Categorical Summary:\n",
      "                            Name   Sex    Ticket            Cabin Embarked\n",
      "count                        418   418       418               91      418\n",
      "unique                       418     2       363               76        3\n",
      "top     Peter, Master. Michael J  male  PC 17608  B57 B59 B63 B66        S\n",
      "freq                           1   266         5                3      270\n"
     ]
    }
   ],
   "source": [
    "# Statistical summary (Numerical and Categorical)\n",
    "\n",
    "print (\"\\nNumerical Summary:\")\n",
    "print (df.describe())\n",
    "\n",
    "print(\"\\nCategorical Summary:\")\n",
    "print(df.describe(include='object'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bec4f5",
   "metadata": {},
   "source": [
    "A. Dimensions and Data Types:\n",
    "\n",
    "1. Dimensions (Dataset Size): The Titanic dataset (train.csv) contains [418] records (passengers) and [12] columns (variables/features).\n",
    "\n",
    "2. Data Types (Dtypes): Three main data types have been identified that will guide the cleaning process:\n",
    "\n",
    "    * Numeric: int64 and float 64 (Examples: `Age`, `Fare`, `Pclass`).\n",
    "    * Categorical/Text: object (Examples: `Name`, `Sex`, `Cabin`, `Embarked`, `Ticket`).\n",
    "\n",
    "3. Columns of Low Relevance: Passengerld and Ticked are unique identifiers or high-cardinality variables (many unique values). It is recommended to remove them in the early stages of Feature Engineering to simplify the model.\n",
    "\n",
    "B. Detection and Plan of Missing Values (Missing Data)\n",
    "\n",
    "Based on the inspection of `df.info()`, the next columns have missing data:\n",
    "\n",
    "| Column | Total of Rows (418) | No-Null Count | Missing Values | Null Percentage (Aprox.) | Treatment Plan |\n",
    "| :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "| **Cabin** | 418 | [91] | [327] | **~77.04%** | **Elimination:** The percentage is critical. The column will be deleted. |\n",
    "| **Age** | 418 | [332] | [86] | **~20.57%** | **Numerical Imputation:** It will be filled with the **Median** to preserve the distribution without bias from *outliers*. |\n",
    "| **Embarked** | 418 | [418] | [0] | **~0.48%** | **Categorical Imputacion:** It will be filled in with the **Mode**, given the low incidence of null values.|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
